{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00a90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba5c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:37<00:00, 4579125.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training dataset 다운로드\n",
    "cifar10_train = dataset.CIFAR10(root = \"./\", # 데이터셋을 저장할 위치\n",
    "                            train = True,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)\n",
    "# Testing dataset 다운로드\n",
    "cifar10_test = dataset.CIFAR10(root = \"./\",\n",
    "                            train = False,\n",
    "                            transform = transform.ToTensor(),\n",
    "                            download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a135e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dataset_size(data):\n",
    "    if isinstance(data, (list, tuple, dict, torch.utils.data.Dataset)):\n",
    "        return len(data)\n",
    "    elif isinstance(data, torch.Tensor) or isinstance(data, np.ndarray):\n",
    "        return data.shape[0]\n",
    "    elif hasattr(data, '__len__'):\n",
    "        return len(data)\n",
    "    elif hasattr(data, 'shape'):\n",
    "        return data.shape[0]\n",
    "    else:\n",
    "        raise TypeError(\"지원하지 않는 데이터셋 타입입니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3de3469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 데이터 크기: 50000\n"
     ]
    }
   ],
   "source": [
    "train_len = infer_dataset_size(cifar10_train)\n",
    "print(\"Training 데이터 크기:\", train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f9d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet (nn.Module):\n",
    "  def __init__ (self):\n",
    "    super(ResNet, self).__init__()\n",
    "\n",
    "    self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)    # Convolution: [3x3x3] x 16, s1, p1\n",
    "    self.conv1_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x16] x 32, s1, p1\n",
    "\n",
    "    self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)   # Convolution: [3x3x32] x 32, s1, p1\n",
    "    self.conv2_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)   # Convolution: [3x3x64] x 64, s1, p1\n",
    "\n",
    "    self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)  # Convolution: [3x3x64] x 128, s1, p1\n",
    "    self.conv3_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1) # Convolution: [3x3x128] x 256, s1, p1\n",
    "\n",
    "    self.fc1 = nn.Linear(4096, 512)   # Fully connected layer: 4096 x 512\n",
    "    self.fc2 = nn.Linear(512, 256)    # Fully connected layer: 512 x 256\n",
    "    self.fc3 = nn.Linear(256, 10)     # Fully connected layer: 256 x 10\n",
    "\n",
    "    self.conv1_skip = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,padding=1)\n",
    "    self.conv2_skip = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,padding=1)\n",
    "    self.conv3_skip = nn.Conv2d(in_channels=64,out_channels=256,kernel_size=3,padding=1)\n",
    "\n",
    "    # 파라미터를 가지지 않은 layer는 한 번만 선언해도 문제 없음\n",
    "    self.relu = nn.ReLU()\n",
    "    self.avgPool2d = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    input_feature1 = x\n",
    "\n",
    "    # convolution layers\n",
    "    out = self.relu(self.conv1_1(x))\n",
    "    out = self.relu(self.conv1_2(out))\n",
    "    input_skip1 = self.relu(self.conv1_skip(input_feature1))\n",
    "    out = torch.add(out, input_skip1)\n",
    "    out = self.avgPool2d(out)\n",
    "  \n",
    "    input_feature2 = out\n",
    "\n",
    "    out = self.relu(self.conv2_1(out))\n",
    "    out = self.relu(self.conv2_2(out))\n",
    "    input_skip2 = self.relu(self.conv2_skip(input_feature2))\n",
    "    out = torch.add(out,input_skip2)\n",
    "    out = self.avgPool2d(out)\n",
    "\n",
    "    \n",
    "\n",
    "    input_feature3 = out\n",
    "\n",
    "    out = self.relu(self.conv3_1(out))\n",
    "    out = self.relu(self.conv3_2(out))\n",
    "    input_skip3 = self.relu(self.conv3_skip(input_feature3))\n",
    "    out = torch.add(out,input_skip3)\n",
    "    out = self.avgPool2d(out)\n",
    "\n",
    "    # 평탄화\n",
    "    out = out.reshape(-1, 4096)\n",
    "\n",
    "    # fully connected layers\n",
    "    out = self.relu(self.fc1(out))\n",
    "    out = self.relu(self.fc2(out))\n",
    "    out = self.fc3(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7adfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | Loss = 2.1677 | Time = 5.81 sec\n",
      "Epoch:  2 | Loss = 1.8378 | Time = 5.10 sec\n",
      "Epoch:  3 | Loss = 1.5857 | Time = 4.96 sec\n",
      "Epoch:  4 | Loss = 1.4419 | Time = 5.02 sec\n",
      "Epoch:  5 | Loss = 1.3238 | Time = 4.50 sec\n",
      "Epoch:  6 | Loss = 1.2104 | Time = 4.51 sec\n",
      "Epoch:  7 | Loss = 1.1208 | Time = 4.34 sec\n",
      "Epoch:  8 | Loss = 1.0192 | Time = 4.73 sec\n",
      "Epoch:  9 | Loss = 0.9276 | Time = 5.16 sec\n",
      "Epoch: 10 | Loss = 0.8355 | Time = 5.50 sec\n",
      "Epoch: 11 | Loss = 0.7336 | Time = 5.19 sec\n",
      "Epoch: 12 | Loss = 0.6475 | Time = 5.11 sec\n",
      "Epoch: 13 | Loss = 0.5427 | Time = 5.51 sec\n",
      "Epoch: 14 | Loss = 0.4473 | Time = 5.22 sec\n",
      "Epoch: 15 | Loss = 0.3515 | Time = 5.08 sec\n",
      "Epoch: 16 | Loss = 0.2748 | Time = 4.95 sec\n",
      "Epoch: 17 | Loss = 0.2058 | Time = 4.83 sec\n",
      "Epoch: 18 | Loss = 0.1675 | Time = 5.06 sec\n",
      "Epoch: 19 | Loss = 0.1301 | Time = 4.78 sec\n",
      "Epoch: 20 | Loss = 0.1113 | Time = 4.59 sec\n",
      "Learning finished!\n",
      "Accuracy: 0.6843000054359436\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters 지정\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "network = ResNet()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)\n",
    "data_loader = DataLoader(dataset=cifar10_train,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "# 학습을 위한 반복문 진행\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "\n",
    "network = network.to(device)\n",
    "# 학습 루프\n",
    "for epoch in range(training_epochs):\n",
    "    start_time = time.time()  # ⏱️ 에포크 시작 시간 기록\n",
    "\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for img, label in data_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        pred = network(img)\n",
    "        loss = loss_function(pred, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += loss / total_batch\n",
    "\n",
    "    end_time = time.time()  # ⏱️ 에포크 종료 시간\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    print(f'Epoch: {epoch+1:2d} | Loss = {avg_cost:.4f} | Time = {epoch_time:.2f} sec')\n",
    "\n",
    "print('Learning finished!')\n",
    "\n",
    "# 정확도 평가\n",
    "network = network.to('cpu')\n",
    "with torch.no_grad():\n",
    "    img_test = torch.tensor(np.transpose(cifar10_test.data, (0, 3, 1, 2))) / 255.\n",
    "    label_test = torch.tensor(cifar10_test.targets)\n",
    "\n",
    "    prediction = network(img_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == label_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1db6b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Total MFLOPs  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::cudnn_convolution         6.52%     512.400us         6.52%     512.400us      56.933us     163.319ms        93.35%     163.319ms      18.147ms           0 b           0 b      62.50 Mb      62.50 Mb             9            --  \n",
      "                             aten::convolution_backward        13.68%       1.076ms        17.56%       1.381ms     153.411us       3.256ms         1.86%       3.604ms     400.444us           0 b           0 b      24.70 Mb      22.41 Mb             9            --  \n",
      "                                        aten::clamp_min         2.47%     193.900us         2.47%     193.900us      17.627us       1.418ms         0.81%       1.418ms     128.909us           0 b           0 b      62.79 Mb      62.79 Mb            11            --  \n",
      "autograd::engine::evaluate_function: torch::autograd...         3.85%     302.900us        11.20%     880.700us      36.696us       1.037ms         0.59%       1.737ms      72.375us           0 b           0 b           0 b           0 b            24            --  \n",
      "                                              aten::add         0.68%      53.200us         0.68%      53.200us      17.733us     880.000us         0.50%     880.000us     293.333us           0 b           0 b      25.00 Mb      25.00 Mb             3         6.554  \n",
      "                               aten::threshold_backward         2.19%     172.000us         2.19%     172.000us      15.636us     678.000us         0.39%     678.000us      61.636us           0 b           0 b      63.14 Mb      63.14 Mb            11            --  \n",
      "                                      aten::result_type         0.04%       3.000us         0.04%       3.000us       0.125us     467.000us         0.27%     467.000us      19.458us           0 b           0 b           0 b           0 b            24            --  \n",
      "                                             aten::add_         2.11%     165.900us         2.11%     165.900us      15.082us     396.000us         0.23%     396.000us      36.000us           0 b           0 b           0 b           0 b            11            --  \n",
      "                                              aten::sum         3.91%     307.500us         4.05%     318.600us      26.550us     361.000us         0.21%     374.000us      31.167us           0 b           0 b       9.00 Kb       9.00 Kb            12            --  \n",
      "                              aten::avg_pool2d_backward         0.71%      55.700us         0.71%      55.700us      18.567us     357.000us         0.20%     357.000us     119.000us           0 b           0 b      25.00 Mb      25.00 Mb             3            --  \n",
      "                                                 detach         0.42%      33.400us         0.42%      33.400us       1.392us     349.000us         0.20%     349.000us      14.542us           0 b           0 b           0 b           0 b            24            --  \n",
      "                                    aten::_foreach_add_         3.28%     257.600us         3.31%     260.600us     260.600us     235.000us         0.13%     702.000us     702.000us           0 b           0 b           0 b           0 b             1            --  \n",
      "                                                aten::t         2.25%     176.600us         4.68%     368.000us      24.533us     220.000us         0.13%     402.000us      26.800us           0 b           0 b           0 b           0 b            15            --  \n",
      "                                               aten::mm         2.11%     166.100us         2.11%     166.100us      27.683us     220.000us         0.13%     220.000us      36.667us           0 b           0 b      10.37 Mb      10.37 Mb             6       892.314  \n",
      "                                           aten::detach         3.34%     262.300us         3.76%     295.700us      12.321us     218.000us         0.12%     567.000us      23.625us           0 b           0 b           0 b           0 b            24            --  \n",
      "                        torch::autograd::AccumulateGrad         3.59%     282.100us         7.35%     577.800us      24.075us     133.000us         0.08%     700.000us      29.167us           0 b           0 b           0 b           0 b            24            --  \n",
      "                                            aten::addmm         1.97%     155.000us         1.97%     155.000us      51.667us     121.000us         0.07%     121.000us      40.333us           0 b           0 b     304.00 Kb     304.00 Kb             3       446.157  \n",
      "                                       aten::avg_pool2d         0.85%      67.100us         0.85%      67.100us      22.367us     116.000us         0.07%     116.000us      38.667us           0 b           0 b       6.25 Mb       6.25 Mb             3            --  \n",
      "                                        aten::transpose         2.25%     177.200us         2.43%     191.400us      12.760us     115.000us         0.07%     182.000us      12.133us           0 b           0 b           0 b           0 b            15            --  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         1.51%     118.400us         9.09%     714.500us     238.167us     114.000us         0.07%     649.000us     216.333us           0 b           0 b       8.51 Mb      -1.86 Mb             3            --  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.862ms\n",
      "Self CUDA time total: 174.960ms\n",
      "\n",
      "Time = 5.76 sec\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.profiler\n",
    "import time\n",
    "\n",
    "# model = ResNet().cuda()\n",
    "model = ResNet().cuda()\n",
    "model.train()  # 학습 모드\n",
    "\n",
    "# 더미 입력과 레이블 준비\n",
    "dummy_input = torch.randn(100, 3, 32, 32).cuda()  # 배치 사이즈 100\n",
    "dummy_target = torch.randint(0, 10, (100,)).cuda()\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 프로파일링 시작\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True,\n",
    "    with_flops=True,   # (선택) FLOPS도 계산\n",
    ") as prof:\n",
    "    # 학습 루프 한 번\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(dummy_input)\n",
    "    loss = criterion(output, dummy_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "\n",
    "# 결과 출력\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=20))\n",
    "t = (end_time - start_time) * 500\n",
    "print(f'Time = {t:.2f} sec')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518196c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Self CPU %</th>\n",
       "      <th>Self CPU</th>\n",
       "      <th>CPU total %</th>\n",
       "      <th>CPU total</th>\n",
       "      <th>CPU time avg</th>\n",
       "      <th>Self CUDA</th>\n",
       "      <th>Self CUDA %</th>\n",
       "      <th>CUDA total</th>\n",
       "      <th>CUDA time avg</th>\n",
       "      <th>CPU Mem</th>\n",
       "      <th>Self CPU Mem</th>\n",
       "      <th>CUDA Mem</th>\n",
       "      <th>Self CUDA Mem</th>\n",
       "      <th># of Calls</th>\n",
       "      <th>Total MFLOPs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::cudnn_convolution</td>\n",
       "      <td>6.52%</td>\n",
       "      <td>512.4</td>\n",
       "      <td>6.52%</td>\n",
       "      <td>512.4</td>\n",
       "      <td>56.933</td>\n",
       "      <td>163319.0</td>\n",
       "      <td>93.35%</td>\n",
       "      <td>163319.0</td>\n",
       "      <td>18147.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>62.50 Mb</td>\n",
       "      <td>62.50 Mb</td>\n",
       "      <td>9</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::convolution_backward</td>\n",
       "      <td>13.68%</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>17.56%</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>153.411</td>\n",
       "      <td>3256.0</td>\n",
       "      <td>1.86%</td>\n",
       "      <td>3604.0</td>\n",
       "      <td>400.444</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>24.70 Mb</td>\n",
       "      <td>22.41 Mb</td>\n",
       "      <td>9</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::clamp_min</td>\n",
       "      <td>2.47%</td>\n",
       "      <td>193.9</td>\n",
       "      <td>2.47%</td>\n",
       "      <td>193.9</td>\n",
       "      <td>17.627</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>128.909</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>62.79 Mb</td>\n",
       "      <td>62.79 Mb</td>\n",
       "      <td>11</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autograd::engine::evaluate_function: torch::au...</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>302.9</td>\n",
       "      <td>11.20%</td>\n",
       "      <td>880.7</td>\n",
       "      <td>36.696</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>72.375</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>24</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::add</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>53.2</td>\n",
       "      <td>17.733</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>880.0</td>\n",
       "      <td>293.333</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>25.00 Mb</td>\n",
       "      <td>25.00 Mb</td>\n",
       "      <td>3</td>\n",
       "      <td>6.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>aten::empty_like</td>\n",
       "      <td>0.21%</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.29%</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>512 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>aten::zero_</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.41%</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>autograd::engine::evaluate_function: LogSoftma...</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.56%</td>\n",
       "      <td>43.7</td>\n",
       "      <td>43.700</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>-4.00 Kb</td>\n",
       "      <td>-8.00 Kb</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>aten::empty_strided</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>512 b</td>\n",
       "      <td>512 b</td>\n",
       "      <td>1</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[memory]</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0 b</td>\n",
       "      <td>0 b</td>\n",
       "      <td>-84.22 Mb</td>\n",
       "      <td>-84.22 Mb</td>\n",
       "      <td>62</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name Self CPU %  Self CPU  \\\n",
       "0                             aten::cudnn_convolution      6.52%     512.4   \n",
       "1                          aten::convolution_backward     13.68%    1076.0   \n",
       "2                                     aten::clamp_min      2.47%     193.9   \n",
       "3   autograd::engine::evaluate_function: torch::au...      3.85%     302.9   \n",
       "4                                           aten::add      0.68%      53.2   \n",
       "..                                                ...        ...       ...   \n",
       "59                                   aten::empty_like      0.21%      16.8   \n",
       "60                                        aten::zero_      0.19%      15.3   \n",
       "61  autograd::engine::evaluate_function: LogSoftma...      0.19%      15.0   \n",
       "62                                aten::empty_strided      0.08%       6.2   \n",
       "63                                           [memory]      0.00%       0.0   \n",
       "\n",
       "   CPU total %  CPU total  CPU time avg  Self CUDA Self CUDA %  CUDA total  \\\n",
       "0        6.52%      512.4        56.933   163319.0      93.35%    163319.0   \n",
       "1       17.56%     1381.0       153.411     3256.0       1.86%      3604.0   \n",
       "2        2.47%      193.9        17.627     1418.0       0.81%      1418.0   \n",
       "3       11.20%      880.7        36.696     1037.0       0.59%      1737.0   \n",
       "4        0.68%       53.2        17.733      880.0       0.50%       880.0   \n",
       "..         ...        ...           ...        ...         ...         ...   \n",
       "59       0.29%       23.0        23.000        3.0       0.00%         5.0   \n",
       "60       0.41%       32.0        32.000        3.0       0.00%        22.0   \n",
       "61       0.56%       43.7        43.700        3.0       0.00%        30.0   \n",
       "62       0.08%        6.2         6.200        2.0       0.00%         2.0   \n",
       "63       0.00%        0.0         0.000        0.0       0.00%         0.0   \n",
       "\n",
       "    CUDA time avg CPU Mem Self CPU Mem   CUDA Mem Self CUDA Mem # of Calls  \\\n",
       "0       18147.000     0 b          0 b   62.50 Mb      62.50 Mb          9   \n",
       "1         400.444     0 b          0 b   24.70 Mb      22.41 Mb          9   \n",
       "2         128.909     0 b          0 b   62.79 Mb      62.79 Mb         11   \n",
       "3          72.375     0 b          0 b        0 b           0 b         24   \n",
       "4         293.333     0 b          0 b   25.00 Mb      25.00 Mb          3   \n",
       "..            ...     ...          ...        ...           ...        ...   \n",
       "59          5.000     0 b          0 b      512 b           0 b          1   \n",
       "60         22.000     0 b          0 b        0 b           0 b          1   \n",
       "61         30.000     0 b          0 b   -4.00 Kb      -8.00 Kb          1   \n",
       "62          2.000     0 b          0 b      512 b         512 b          1   \n",
       "63          0.000     0 b          0 b  -84.22 Mb     -84.22 Mb         62   \n",
       "\n",
       "   Total MFLOPs  \n",
       "0            --  \n",
       "1            --  \n",
       "2            --  \n",
       "3            --  \n",
       "4         6.554  \n",
       "..          ...  \n",
       "59           --  \n",
       "60           --  \n",
       "61           --  \n",
       "62           --  \n",
       "63           --  \n",
       "\n",
       "[64 rows x 16 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 프로파일링 결과 문자열\n",
    "profile_table_str = prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=100)\n",
    "\n",
    "# 줄 단위로 분리\n",
    "lines = profile_table_str.split('\\n')\n",
    "\n",
    "# 유효한 데이터 줄만 필터링\n",
    "data_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line or line.startswith('-') or 'Self CPU time total' in line or 'Self CUDA time total' in line:\n",
    "        continue\n",
    "    data_lines.append(line)\n",
    "\n",
    "# 첫 번째 줄은 헤더, 나머지는 데이터\n",
    "header_line = data_lines[0]\n",
    "data_lines = data_lines[1:]\n",
    "\n",
    "# 헤더 컬럼명 파싱 (공백 기준 split) + strip 추가\n",
    "columns = [col.strip() for col in header_line.split('  ') if col.strip()]\n",
    "\n",
    "# 데이터 파싱\n",
    "parsed_data = []\n",
    "for line in data_lines:\n",
    "    fields = [field.strip() for field in line.split('  ') if field.strip()]\n",
    "    if len(fields) == len(columns):\n",
    "        parsed_data.append(fields)\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(parsed_data, columns=columns)\n",
    "\n",
    "# 🔥 시간 컬럼 리스트\n",
    "time_columns = ['Self CPU', 'CPU total', 'CPU time avg', 'Self CUDA', 'CUDA total', 'CUDA time avg']\n",
    "\n",
    "# 시간 컬럼 처리 함수\n",
    "def convert_to_ms(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        if x.endswith('us'):\n",
    "            return float(x.replace('us', '')) / 1000  # us(마이크로초) -> ms(밀리초)\n",
    "        elif x.endswith('ms'):\n",
    "            return float(x.replace('ms', ''))          # ms는 그대로\n",
    "        elif x.endswith('s'):\n",
    "            return float(x.replace('s', '')) * 1000     # s(초) -> ms로 변환\n",
    "        else:\n",
    "            return float(x)\n",
    "    else:\n",
    "        return x  # 이미 숫자형이면 그대로\n",
    "\n",
    "\n",
    "# 모든 시간 컬럼에 적용\n",
    "for col in time_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(convert_to_us)\n",
    "\n",
    "# 결과 확인\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c5b6fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Self CUDA</th>\n",
       "      <th>CUDA total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::cudnn_convolution</td>\n",
       "      <td>259293.0</td>\n",
       "      <td>259293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::add_</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>5404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::convolution_backward</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>3595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::clamp_min</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::threshold_backward</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>aten::empty_strided</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NllLossBackward0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>aten::resize_</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[memory]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>aten::result_type</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  Self CUDA  CUDA total\n",
       "0      aten::cudnn_convolution   259293.0    259293.0\n",
       "1                   aten::add_     5404.0      5404.0\n",
       "2   aten::convolution_backward     3248.0      3595.0\n",
       "3              aten::clamp_min     1145.0      1145.0\n",
       "4     aten::threshold_backward     1121.0      1121.0\n",
       "..                         ...        ...         ...\n",
       "60         aten::empty_strided        2.0         2.0\n",
       "61            NllLossBackward0        2.0        75.0\n",
       "62               aten::resize_        1.0         1.0\n",
       "63                    [memory]        0.0         0.0\n",
       "64           aten::result_type        0.0         0.0\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced = df[['Name','Self CUDA', 'CUDA total']].copy()\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "384e8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Self CUDA</th>\n",
       "      <th>CUDA total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::cudnn_convolution</td>\n",
       "      <td>259293.0</td>\n",
       "      <td>259293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::add_</td>\n",
       "      <td>5404.0</td>\n",
       "      <td>5404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::convolution_backward</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>3595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::clamp_min</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::threshold_backward</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>autograd::engine::evaluate_function: torch::au...</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aten::reshape</td>\n",
       "      <td>825.0</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aten::avg_pool2d_backward</td>\n",
       "      <td>373.0</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aten::sum</td>\n",
       "      <td>333.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aten::_foreach_add_</td>\n",
       "      <td>272.0</td>\n",
       "      <td>334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aten::convolution</td>\n",
       "      <td>266.0</td>\n",
       "      <td>265881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>autograd::engine::evaluate_function: AddmmBack...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aten::add</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aten::t</td>\n",
       "      <td>210.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aten::detach</td>\n",
       "      <td>210.0</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>torch::autograd::AccumulateGrad</td>\n",
       "      <td>166.0</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aten::mm</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aten::addmm</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AddmmBackward0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aten::transpose</td>\n",
       "      <td>126.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  Self CUDA  CUDA total\n",
       "0                             aten::cudnn_convolution   259293.0    259293.0\n",
       "1                                          aten::add_     5404.0      5404.0\n",
       "2                          aten::convolution_backward     3248.0      3595.0\n",
       "3                                     aten::clamp_min     1145.0      1145.0\n",
       "4                            aten::threshold_backward     1121.0      1121.0\n",
       "5   autograd::engine::evaluate_function: torch::au...      840.0      1326.0\n",
       "6                                       aten::reshape      825.0       839.0\n",
       "7                           aten::avg_pool2d_backward      373.0       373.0\n",
       "8                                           aten::sum      333.0       346.0\n",
       "9                                 aten::_foreach_add_      272.0       334.0\n",
       "10                                  aten::convolution      266.0    265881.0\n",
       "11  autograd::engine::evaluate_function: AddmmBack...      253.0       844.0\n",
       "12                                          aten::add      219.0       219.0\n",
       "13                                            aten::t      210.0       400.0\n",
       "14                                       aten::detach      210.0       320.0\n",
       "15                    torch::autograd::AccumulateGrad      166.0       486.0\n",
       "16                                           aten::mm      152.0       152.0\n",
       "17                                        aten::addmm      137.0       137.0\n",
       "18                                     AddmmBackward0      128.0       508.0\n",
       "19                                    aten::transpose      126.0       190.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top20_df = df_reduced.sort_values(by='Self CUDA', ascending=False).head(20)\n",
    "\n",
    "# 결과 출력\n",
    "top20_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
